{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Đường dẫn đến file HDF5\n",
    "# hdf5_file_path = \"model.hdf5\"\n",
    "\n",
    "# # Đọc file HDF5\n",
    "# with h5py.File(hdf5_file_path, 'r') as hdf5_file:\n",
    "#     # Lấy danh sách các khóa (keys) trong file\n",
    "#     keys = list(hdf5_file.keys())\n",
    "    \n",
    "#     # In thông tin về các khóa\n",
    "#     print(f\"Keys in HDF5 file: {keys}\")\n",
    "\n",
    "#     # Đọc dữ liệu từ các nhóm (groups) và tập tin (datasets)\n",
    "#     for key in keys:\n",
    "#         # Kiểm tra nếu key là một nhóm\n",
    "#         if isinstance(hdf5_file[key], h5py.Group):\n",
    "#             print(f\"Group: {key}\")\n",
    "#             # Đọc dữ liệu từ nhóm (group) tại đây nếu cần\n",
    "#         elif isinstance(hdf5_file[key], h5py.Dataset):\n",
    "#             print(f\"Dataset: {key}\")\n",
    "#             # Đọc dữ liệu từ tập tin (dataset) tại đây nếu cần\n",
    "#             data = hdf5_file[key][()]\n",
    "#             print(f\"Data: {data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Tải mô hình từ file HDF5\n",
    "# with h5py.File(hdf5_file_path, 'r') as hdf5_file:\n",
    "#     # Load các thông tin cần thiết từ file HDF5 (tuỳ thuộc vào cấu trúc của file)\n",
    "#     # Ví dụ: input_shape, num_classes, load_weights...\n",
    "\n",
    "#     # Hàm dự đoán\n",
    "#     def predict(data):\n",
    "#         # Thực hiện các bước dự đoán với mô hình đã tải\n",
    "#         # Trả về kết quả dự đoán\n",
    "\n",
    "#     # Streamlit App\n",
    "#     st.title(\"Streamlit HDF5 Model Deployment\")\n",
    "#     user_input = st.text_input(\"Nhập dữ liệu cho dự đoán:\")\n",
    "#     if st.button(\"Dự đoán\"):\n",
    "#         # Chuyển đổi dữ liệu người dùng nhập vào định dạng phù hợp\n",
    "#         user_data = np.random.rand(10, *input_shape)  # Thay thế bằng dữ liệu thực tế từ người dùng\n",
    "#         # Thực hiện dự đoán\n",
    "#         prediction = predict(user_data)\n",
    "#         st.write(f\"Kết quả dự đoán: {prediction}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"default\": shape (1000,), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "# check dataset name and shape, type\n",
    "# <HDF5 dataset \"default\": shape (1000,), type \"<f8\">\n",
    "train_filename = 'model.hdf5'\n",
    "with h5py.File(train_filename, \"r\") as f:\n",
    "    for file_key in f.keys():\n",
    "        group = f[file_key]\n",
    "        print(group)\n",
    "        try:\n",
    "            for group_key in group.keys():\n",
    "                group2 = group[group_key]\n",
    "                print(f\"---->{group2}\")\n",
    "                for group_key2 in group2.keys():\n",
    "                        print(f\"--------->{group2[group_key2]}\")\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "# train\n",
    "train_filename = 'model.hdf5'\n",
    "datasets = []\n",
    "with h5py.File(train_filename, \"r\") as f:\n",
    "    for file_key in f.keys():\n",
    "        group = f[file_key]\n",
    "        if isinstance(group, h5py._hl.dataset.Dataset):\n",
    "            datasets.append(np.array(group))\n",
    "            continue\n",
    "        for group_key in group.keys():\n",
    "            group2 = group[group_key]\n",
    "            if isinstance(group2, h5py._hl.dataset.Dataset):\n",
    "                datasets.append(np.array(group2))\n",
    "                continue\n",
    "            for group_key2 in group2.keys():\n",
    "                group3 = group2[group_key2]\n",
    "                if isinstance(group3, h5py._hl.dataset.Dataset):\n",
    "                    datasets.append(np.array(group3))\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "__abs__\n",
      "__add__\n",
      "__and__\n",
      "__array__\n",
      "__array_finalize__\n",
      "__array_function__\n",
      "__array_interface__\n",
      "__array_prepare__\n",
      "__array_priority__\n",
      "__array_struct__\n",
      "__array_ufunc__\n",
      "__array_wrap__\n",
      "__bool__\n",
      "__class__\n",
      "__class_getitem__\n",
      "__complex__\n",
      "__contains__\n",
      "__copy__\n",
      "__deepcopy__\n",
      "__delattr__\n",
      "__delitem__\n",
      "__dir__\n",
      "__divmod__\n",
      "__dlpack__\n",
      "__dlpack_device__\n",
      "__doc__\n",
      "__eq__\n",
      "__float__\n",
      "__floordiv__\n",
      "__format__\n",
      "__ge__\n",
      "__getattribute__\n",
      "__getitem__\n",
      "__gt__\n",
      "__hash__\n",
      "__iadd__\n",
      "__iand__\n",
      "__ifloordiv__\n",
      "__ilshift__\n",
      "__imatmul__\n",
      "__imod__\n",
      "__imul__\n",
      "__index__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__int__\n",
      "__invert__\n",
      "__ior__\n",
      "__ipow__\n",
      "__irshift__\n",
      "__isub__\n",
      "__iter__\n",
      "__itruediv__\n",
      "__ixor__\n",
      "__le__\n",
      "__len__\n",
      "__lshift__\n",
      "__lt__\n",
      "__matmul__\n",
      "__mod__\n",
      "__mul__\n",
      "__ne__\n",
      "__neg__\n",
      "__new__\n",
      "__or__\n",
      "__pos__\n",
      "__pow__\n",
      "__radd__\n",
      "__rand__\n",
      "__rdivmod__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__rfloordiv__\n",
      "__rlshift__\n",
      "__rmatmul__\n",
      "__rmod__\n",
      "__rmul__\n",
      "__ror__\n",
      "__rpow__\n",
      "__rrshift__\n",
      "__rshift__\n",
      "__rsub__\n",
      "__rtruediv__\n",
      "__rxor__\n",
      "__setattr__\n",
      "__setitem__\n",
      "__setstate__\n",
      "__sizeof__\n",
      "__str__\n",
      "__sub__\n",
      "__subclasshook__\n",
      "__truediv__\n",
      "__xor__\n",
      "all\n",
      "any\n",
      "argmax\n",
      "argmin\n",
      "argpartition\n",
      "argsort\n",
      "astype\n",
      "base\n",
      "byteswap\n",
      "choose\n",
      "clip\n",
      "compress\n",
      "conj\n",
      "conjugate\n",
      "copy\n",
      "ctypes\n",
      "cumprod\n",
      "cumsum\n",
      "data\n",
      "diagonal\n",
      "dot\n",
      "dtype\n",
      "dump\n",
      "dumps\n",
      "fill\n",
      "flags\n",
      "flat\n",
      "flatten\n",
      "getfield\n",
      "imag\n",
      "item\n",
      "itemset\n",
      "itemsize\n",
      "max\n",
      "mean\n",
      "min\n",
      "nbytes\n",
      "ndim\n",
      "newbyteorder\n",
      "nonzero\n",
      "partition\n",
      "prod\n",
      "ptp\n",
      "put\n",
      "ravel\n",
      "real\n",
      "repeat\n",
      "reshape\n",
      "resize\n",
      "round\n",
      "searchsorted\n",
      "setfield\n",
      "setflags\n",
      "shape\n",
      "size\n",
      "sort\n",
      "squeeze\n",
      "std\n",
      "strides\n",
      "sum\n",
      "swapaxes\n",
      "take\n",
      "tobytes\n",
      "tofile\n",
      "tolist\n",
      "tostring\n",
      "trace\n",
      "transpose\n",
      "var\n",
      "view\n"
     ]
    }
   ],
   "source": [
    "# import h5py\n",
    "\n",
    "# # Open the HDF5 file\n",
    "# with h5py.File('model.hdf5', 'r') as file:\n",
    "#     # Get the keys of all datasets in the file\n",
    "#     dataset_keys = list(file.keys())\n",
    "\n",
    "# # Print the dataset keys\n",
    "# print(\"Available datasets:\")\n",
    "# for key in dataset_keys:\n",
    "#     print(key)\n",
    "\n",
    "# # Prompt the user to input the model dataset name\n",
    "# model_name = input(\"Enter the name of the model dataset: \")\n",
    "\n",
    "# # Load the model using the specified dataset name\n",
    "# with h5py.File('model.hdf5', 'r') as file:\n",
    "#     model = file.get(model_name)\n",
    "\n",
    "# # Check if the model was loaded successfully\n",
    "# if model is not None:\n",
    "#     print(\"Model loaded successfully.\")\n",
    "# else:\n",
    "#     print(\"Failed to load the model.\")\n",
    "import h5py\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Tải mô hình từ tệp HDF5\n",
    "def load_model_from_hdf5(file_path):\n",
    "    model = None\n",
    "    with h5py.File(file_path, \"r\") as file:\n",
    "        model = file.get(\"default\")  # Thay \"model_name\" bằng tên thực sự của dataset\n",
    "        model = model[()] if model is not None else None\n",
    "    return model\n",
    "\n",
    "# In danh sách các phương thức và thuộc tính có sẵn trong model\n",
    "def print_model_attributes(model):\n",
    "    attributes = dir(model)\n",
    "    for attribute in attributes:\n",
    "        print(attribute)\n",
    "\n",
    "# Đường dẫn tới tệp HDF5 của mô hình\n",
    "hdf5_file_path = 'model.hdf5'  # Thay 'model.hdf5' bằng đường dẫn thực tế đến tệp HDF5 của bạn\n",
    "\n",
    "# Tải mô hình từ tệp HDF5\n",
    "model = load_model_from_hdf5(hdf5_file_path)\n",
    "\n",
    "# Kiểm tra các phương thức và thuộc tính có sẵn trong model\n",
    "print_model_attributes(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

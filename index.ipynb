{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Đường dẫn đến file HDF5\n",
    "# hdf5_file_path = \"model.hdf5\"\n",
    "\n",
    "# # Đọc file HDF5\n",
    "# with h5py.File(hdf5_file_path, 'r') as hdf5_file:\n",
    "#     # Lấy danh sách các khóa (keys) trong file\n",
    "#     keys = list(hdf5_file.keys())\n",
    "    \n",
    "#     # In thông tin về các khóa\n",
    "#     print(f\"Keys in HDF5 file: {keys}\")\n",
    "\n",
    "#     # Đọc dữ liệu từ các nhóm (groups) và tập tin (datasets)\n",
    "#     for key in keys:\n",
    "#         # Kiểm tra nếu key là một nhóm\n",
    "#         if isinstance(hdf5_file[key], h5py.Group):\n",
    "#             print(f\"Group: {key}\")\n",
    "#             # Đọc dữ liệu từ nhóm (group) tại đây nếu cần\n",
    "#         elif isinstance(hdf5_file[key], h5py.Dataset):\n",
    "#             print(f\"Dataset: {key}\")\n",
    "#             # Đọc dữ liệu từ tập tin (dataset) tại đây nếu cần\n",
    "#             data = hdf5_file[key][()]\n",
    "#             print(f\"Data: {data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Tải mô hình từ file HDF5\n",
    "# with h5py.File(hdf5_file_path, 'r') as hdf5_file:\n",
    "#     # Load các thông tin cần thiết từ file HDF5 (tuỳ thuộc vào cấu trúc của file)\n",
    "#     # Ví dụ: input_shape, num_classes, load_weights...\n",
    "\n",
    "#     # Hàm dự đoán\n",
    "#     def predict(data):\n",
    "#         # Thực hiện các bước dự đoán với mô hình đã tải\n",
    "#         # Trả về kết quả dự đoán\n",
    "\n",
    "#     # Streamlit App\n",
    "#     st.title(\"Streamlit HDF5 Model Deployment\")\n",
    "#     user_input = st.text_input(\"Nhập dữ liệu cho dự đoán:\")\n",
    "#     if st.button(\"Dự đoán\"):\n",
    "#         # Chuyển đổi dữ liệu người dùng nhập vào định dạng phù hợp\n",
    "#         user_data = np.random.rand(10, *input_shape)  # Thay thế bằng dữ liệu thực tế từ người dùng\n",
    "#         # Thực hiện dự đoán\n",
    "#         prediction = predict(user_data)\n",
    "#         st.write(f\"Kết quả dự đoán: {prediction}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"default\": shape (1000,), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "# # check dataset name and shape, type\n",
    "# # <HDF5 dataset \"default\": shape (1000,), type \"<f8\">\n",
    "# train_filename = 'model.hdf5'\n",
    "# with h5py.File(train_filename, \"r\") as f:\n",
    "#     for file_key in f.keys():\n",
    "#         group = f[file_key]\n",
    "#         print(group)\n",
    "#         try:\n",
    "#             for group_key in group.keys():\n",
    "#                 group2 = group[group_key]\n",
    "#                 print(f\"---->{group2}\")\n",
    "#                 for group_key2 in group2.keys():\n",
    "#                         print(f\"--------->{group2[group_key2]}\")\n",
    "#         except AttributeError:\n",
    "#             pass\n",
    "\n",
    "# # train\n",
    "# train_filename = '../input/g2net-detecting-continuous-gravitational-waves/train/004f23b2d.hdf5'\n",
    "# datasets = []\n",
    "# with h5py.File(train_filename, \"r\") as f:\n",
    "#     for file_key in f.keys():\n",
    "#         group = f[file_key]\n",
    "#         if isinstance(group, h5py._hl.dataset.Dataset):\n",
    "#             datasets.append(np.array(group))\n",
    "#             continue\n",
    "#         for group_key in group.keys():\n",
    "#             group2 = group[group_key]\n",
    "#             if isinstance(group2, h5py._hl.dataset.Dataset):\n",
    "#                 datasets.append(np.array(group2))\n",
    "#                 continue\n",
    "#             for group_key2 in group2.keys():\n",
    "#                 group3 = group2[group_key2]\n",
    "#                 if isinstance(group3, h5py._hl.dataset.Dataset):\n",
    "#                     datasets.append(np.array(group3))\n",
    "#                     continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

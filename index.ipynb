{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Đường dẫn đến file HDF5\n",
    "# hdf5_file_path = \"model.hdf5\"\n",
    "\n",
    "# # Đọc file HDF5\n",
    "# with h5py.File(hdf5_file_path, 'r') as hdf5_file:\n",
    "#     # Lấy danh sách các khóa (keys) trong file\n",
    "#     keys = list(hdf5_file.keys())\n",
    "    \n",
    "#     # In thông tin về các khóa\n",
    "#     print(f\"Keys in HDF5 file: {keys}\")\n",
    "\n",
    "#     # Đọc dữ liệu từ các nhóm (groups) và tập tin (datasets)\n",
    "#     for key in keys:\n",
    "#         # Kiểm tra nếu key là một nhóm\n",
    "#         if isinstance(hdf5_file[key], h5py.Group):\n",
    "#             print(f\"Group: {key}\")\n",
    "#             # Đọc dữ liệu từ nhóm (group) tại đây nếu cần\n",
    "#         elif isinstance(hdf5_file[key], h5py.Dataset):\n",
    "#             print(f\"Dataset: {key}\")\n",
    "#             # Đọc dữ liệu từ tập tin (dataset) tại đây nếu cần\n",
    "#             data = hdf5_file[key][()]\n",
    "#             print(f\"Data: {data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Tải mô hình từ file HDF5\n",
    "# with h5py.File(hdf5_file_path, 'r') as hdf5_file:\n",
    "#     # Load các thông tin cần thiết từ file HDF5 (tuỳ thuộc vào cấu trúc của file)\n",
    "#     # Ví dụ: input_shape, num_classes, load_weights...\n",
    "\n",
    "#     # Hàm dự đoán\n",
    "#     def predict(data):\n",
    "#         # Thực hiện các bước dự đoán với mô hình đã tải\n",
    "#         # Trả về kết quả dự đoán\n",
    "\n",
    "#     # Streamlit App\n",
    "#     st.title(\"Streamlit HDF5 Model Deployment\")\n",
    "#     user_input = st.text_input(\"Nhập dữ liệu cho dự đoán:\")\n",
    "#     if st.button(\"Dự đoán\"):\n",
    "#         # Chuyển đổi dữ liệu người dùng nhập vào định dạng phù hợp\n",
    "#         user_data = np.random.rand(10, *input_shape)  # Thay thế bằng dữ liệu thực tế từ người dùng\n",
    "#         # Thực hiện dự đoán\n",
    "#         prediction = predict(user_data)\n",
    "#         st.write(f\"Kết quả dự đoán: {prediction}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataset name and shape, type\n",
    "# <HDF5 dataset \"default\": shape (1000,), type \"<f8\">\n",
    "# train_filename = 'model.hdf5'\n",
    "# with h5py.File(train_filename, \"r\") as f:\n",
    "#     for file_key in f.keys():\n",
    "#         group = f[file_key]\n",
    "#         print(group)\n",
    "#         try:\n",
    "#             for group_key in group.keys():\n",
    "#                 group2 = group[group_key]\n",
    "#                 print(f\"---->{group2}\")\n",
    "#                 for group_key2 in group2.keys():\n",
    "#                         print(f\"--------->{group2[group_key2]}\")\n",
    "#         except AttributeError:\n",
    "#             pass\n",
    "\n",
    "# train\n",
    "train_filename = 'model.hdf5'\n",
    "datasets = []\n",
    "with h5py.File(train_filename, \"r\") as f:\n",
    "    for file_key in f.keys():\n",
    "        group = f[file_key]\n",
    "        if isinstance(group, h5py._hl.dataset.Dataset):\n",
    "            datasets.append(np.array(group))\n",
    "            continue\n",
    "        for group_key in group.keys():\n",
    "            group2 = group[group_key]\n",
    "            if isinstance(group2, h5py._hl.dataset.Dataset):\n",
    "                datasets.append(np.array(group2))\n",
    "                continue\n",
    "            for group_key2 in group2.keys():\n",
    "                group3 = group2[group_key2]\n",
    "                if isinstance(group3, h5py._hl.dataset.Dataset):\n",
    "                    datasets.append(np.array(group3))\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in the root of the file: ['model_weights', 'optimizer_weights']\n",
      "Groups in the root of the file: ['model_weights', 'optimizer_weights']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open object (object 'dataset_name' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     15\u001b[0m     group \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Replace 'group_name' with the actual group name\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\h5py\\_hl\\group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5o.pyx:189\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to synchronously open object (object 'dataset_name' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "file_path = 'model.hdf5'  # Replace with the actual file path\n",
    "\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # List all items (groups and datasets) in the root of the file\n",
    "    items = list(file.keys())\n",
    "    print(\"Items in the root of the file:\", items)\n",
    "\n",
    "    # Identify groups by checking their type\n",
    "    groups = [item for item in items if isinstance(file[item], h5py.Group)]\n",
    "    print(\"Groups in the root of the file:\", groups)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
